{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c051ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ohmeow-blurr -q\n",
    "!pip install bert-score -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d408ff",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytest\n",
      "  Downloading pytest-7.4.0-py3-none-any.whl (323 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting iniconfig (from pytest)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: packaging in ./venv-summarization/lib/python3.10/site-packages (from pytest) (23.1)\n",
      "Collecting pluggy<2.0,>=0.12 (from pytest)\n",
      "  Downloading pluggy-1.2.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in ./venv-summarization/lib/python3.10/site-packages (from pytest) (1.1.1)\n",
      "Collecting tomli>=1.0.0 (from pytest)\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: tomli, pluggy, iniconfig, pytest\n",
      "Successfully installed iniconfig-2.0.0 pluggy-1.2.0 pytest-7.4.0 tomli-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3d6b70",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting blurr\n",
      "  Downloading blurr-0.4.1-py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.9/52.9 kB\u001b[0m \u001b[31m556.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in ./venv-summarization/lib/python3.10/site-packages (from blurr) (6.0)\n",
      "Requirement already satisfied: python-dateutil in ./venv-summarization/lib/python3.10/site-packages (from blurr) (2.8.2)\n",
      "Collecting docopt (from blurr)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting boto3 (from blurr)\n",
      "  Downloading boto3-1.26.165-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m135.9/135.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: smart-open in ./venv-summarization/lib/python3.10/site-packages (from blurr) (6.3.0)\n",
      "Collecting botocore<1.30.0,>=1.29.165 (from boto3->blurr)\n",
      "  Downloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->blurr)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->blurr)\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m830.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in ./venv-summarization/lib/python3.10/site-packages (from python-dateutil->blurr) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in ./venv-summarization/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.165->boto3->blurr) (1.26.16)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=30dea49106be832c3d29b00208e79ae1dd031535fa251f83fde717f00e25d3ff\n",
      "  Stored in directory: /Users/intrro/Library/Caches/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, jmespath, botocore, s3transfer, boto3, blurr\n",
      "Successfully installed blurr-0.4.1 boto3-1.26.165 botocore-1.29.165 docopt-0.6.2 jmespath-1.0.1 s3transfer-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install blurr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d102e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/intrro/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "/Users/intrro/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "/Users/intrro/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/blurr/text/modeling/question_answering.py:31: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  squad_metric = load_metric(\"squad\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The words Extraordinary Claims needs to be banished when talking Extraterrestrials</td>\n",
       "      <td>The words Extraordinary Claims needs to be banished when talking Extraterrestrials page: 1 link I was reading an article that talked about Extraterrestrials the other day and of course at the end of the article the tired line about Extraordinary measures....blah, blah, blah came out towards the end of the article. This needs to stop when talking about Extraterrestrials. It may have been an extraordinary claim 60 years ago but it's not today. With the scientific evidence we have today, many people including one of the top Scientist of our time has reached the conclusion that Extraterrestria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We Know The Truth</td>\n",
       "      <td>link Hey People: I always enjoy your threads, though I think you focus too much on a singular belief issue or pattern, and then it becomes self affirming for you in your research. First, this: But voices actual voices in your head is always mental illness. Sorry, maybe a stress reaction, not to be judgmental, happens to the best and such, just really not what I am trying to convey here. Though I believe you are quite intelligent, I don't think you are qualified, exactly, to make that wholesale, definitive judgement. You even contradict that by referencing Dr. Vinod's \"channeling\" of the Ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UFO over the East Valley here in AZ last night.</td>\n",
       "      <td>UFO over the East Valley here in AZ last night. page: 1 link I couldn't take any pictures I live in West Mesa and the lights were way East. Over Queen Creek area. Lots of my friends and family started calling me right when the lights started happening so I went out to my balcony and there they were. Some people got some pretty good videos. I know some people will say they are flares from a plane but if they are flares why do they dispensary right away. Typically if its a flare it will stay ignited for a short period of time. Kinda nuts. I only witnessed the later 3 lights when it was dark ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Found this nugget in Podesta files Fastwalkers and DSP Program</td>\n",
       "      <td>Found this nugget in Podesta files Fastwalkers and DSP Program page: 1 Found this in the Podesta files, ID # 30433. It's probably well known already, just thought I'd post it just in case. Podesta had forwarded this letter he received onto Leslie Kean. Date: 2015-03-06 John ‚Äì Just tuck this in your UFO files for future reference. One of the government programs that collects hard data on unidentified flying objects is the USAF DSP satellite program. I can add a little insight to rumors published on the web. While I was never fully briefed into the DSP operation directly, I was introduced to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMP event forthcoming?</td>\n",
       "      <td>You have a work bunker? What is it exactly that you do? Man if the world went to crap, the last thing i would be concerned about is ensuring my employer keeps the loot rolling in lol. In fact if that does go down, im jumping in my truck with a motivational \"item\" and coming to work to stock up. The mine site has enough food for 500 people a for 2 weeks at a time. I live out in the country. Im On well water, 1000 liter propane tank for heat and out door boiler. The genny is hooked up to a 400 liter gas storage container. My house that im building up the road from my current house already ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                title  \\\n",
       "0  The words Extraordinary Claims needs to be banished when talking Extraterrestrials   \n",
       "1                                                                   We Know The Truth   \n",
       "2                                     UFO over the East Valley here in AZ last night.   \n",
       "3                      Found this nugget in Podesta files Fastwalkers and DSP Program   \n",
       "4                                                              EMP event forthcoming?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \n",
       "0  The words Extraordinary Claims needs to be banished when talking Extraterrestrials page: 1 link I was reading an article that talked about Extraterrestrials the other day and of course at the end of the article the tired line about Extraordinary measures....blah, blah, blah came out towards the end of the article. This needs to stop when talking about Extraterrestrials. It may have been an extraordinary claim 60 years ago but it's not today. With the scientific evidence we have today, many people including one of the top Scientist of our time has reached the conclusion that Extraterrestria...  \n",
       "1  link Hey People: I always enjoy your threads, though I think you focus too much on a singular belief issue or pattern, and then it becomes self affirming for you in your research. First, this: But voices actual voices in your head is always mental illness. Sorry, maybe a stress reaction, not to be judgmental, happens to the best and such, just really not what I am trying to convey here. Though I believe you are quite intelligent, I don't think you are qualified, exactly, to make that wholesale, definitive judgement. You even contradict that by referencing Dr. Vinod's \"channeling\" of the Ni...  \n",
       "2  UFO over the East Valley here in AZ last night. page: 1 link I couldn't take any pictures I live in West Mesa and the lights were way East. Over Queen Creek area. Lots of my friends and family started calling me right when the lights started happening so I went out to my balcony and there they were. Some people got some pretty good videos. I know some people will say they are flares from a plane but if they are flares why do they dispensary right away. Typically if its a flare it will stay ignited for a short period of time. Kinda nuts. I only witnessed the later 3 lights when it was dark ...  \n",
       "3  Found this nugget in Podesta files Fastwalkers and DSP Program page: 1 Found this in the Podesta files, ID # 30433. It's probably well known already, just thought I'd post it just in case. Podesta had forwarded this letter he received onto Leslie Kean. Date: 2015-03-06 John ‚Äì Just tuck this in your UFO files for future reference. One of the government programs that collects hard data on unidentified flying objects is the USAF DSP satellite program. I can add a little insight to rumors published on the web. While I was never fully briefed into the DSP operation directly, I was introduced to...  \n",
       "4  You have a work bunker? What is it exactly that you do? Man if the world went to crap, the last thing i would be concerned about is ensuring my employer keeps the loot rolling in lol. In fact if that does go down, im jumping in my truck with a motivational \"item\" and coming to work to stock up. The mine site has enough food for 500 people a for 2 weeks at a time. I live out in the country. Im On well water, 1000 liter propane tank for heat and out door boiler. The genny is hooked up to a 400 liter gas storage container. My house that im building up the road from my current house already ha...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fastai.text.all import *\n",
    "from transformers import *\n",
    "from blurr.text.data.all import *\n",
    "from blurr.text.modeling.all import *\n",
    "\n",
    "#Get data\n",
    "df = pd.read_csv('fake.csv', on_bad_lines='skip')\n",
    "df = df.dropna().reset_index()\n",
    "\n",
    "#Select part of data we want to keep\n",
    "df = df[(df['language']=='english') & (df['type']=='bs')].reset_index()\n",
    "df = df[['title','text']]\n",
    "\n",
    "#Clean text\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('\\n',''))\n",
    "\n",
    "#Select only part of it (makes testing faster)\n",
    "articles = df.head(100)\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93281997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator, LANGUAGES\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29cfe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = articles['title'].apply(lambda row: translator.translate(row, dest='ka').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d35298",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = articles['text'].apply(lambda row: translator.translate(row, dest='ka').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91089791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import the pretrained model\n",
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, \n",
    "                                                                  model_cls=BartForConditionalGeneration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dbda05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from blurr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d28a91b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not do one pass in your dataloader, there is something wrong in it. Please see the stack trace below:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/intrro/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The MPS backend is supported on MacOS 12.3+.Current OS version can be queried using `sw_vers`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m blocks \u001b[38;5;241m=\u001b[39m (Seq2SeqTextBlock(batch_tokenize_tfm\u001b[38;5;241m=\u001b[39mhf_batch_tfm), noop)\n\u001b[1;32m     15\u001b[0m dblock \u001b[38;5;241m=\u001b[39m DataBlock(blocks\u001b[38;5;241m=\u001b[39mblocks, get_x\u001b[38;5;241m=\u001b[39mColReader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m), get_y\u001b[38;5;241m=\u001b[39mColReader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m), splitter\u001b[38;5;241m=\u001b[39mRandomSplitter())\n\u001b[0;32m---> 16\u001b[0m dls \u001b[38;5;241m=\u001b[39m \u001b[43mdblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/data/block.py:157\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[0;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m dsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets(source, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    156\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: verbose}\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdsets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mafter_item\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_tfms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mafter_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_tfms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/data/core.py:337\u001b[0m, in \u001b[0;36mFilteredBase.dataloaders\u001b[0;34m(self, bs, shuffle_train, shuffle, val_shuffle, n, path, dl_type, dl_kwargs, device, drop_last, val_bs, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dl \u001b[38;5;241m=\u001b[39m dl_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    336\u001b[0m def_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbs\u001b[39m\u001b[38;5;124m'\u001b[39m:bs \u001b[38;5;28;01mif\u001b[39;00m val_bs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m val_bs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m'\u001b[39m:val_shuffle,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[0;32m--> 337\u001b[0m dls \u001b[38;5;241m=\u001b[39m [dl] \u001b[38;5;241m+\u001b[39m [dl\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(i), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))\n\u001b[1;32m    338\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_subsets)]\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbunch_type(\u001b[38;5;241m*\u001b[39mdls, path\u001b[38;5;241m=\u001b[39mpath, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/data/core.py:337\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    335\u001b[0m dl \u001b[38;5;241m=\u001b[39m dl_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    336\u001b[0m def_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbs\u001b[39m\u001b[38;5;124m'\u001b[39m:bs \u001b[38;5;28;01mif\u001b[39;00m val_bs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m val_bs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m'\u001b[39m:val_shuffle,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[0;32m--> 337\u001b[0m dls \u001b[38;5;241m=\u001b[39m [dl] \u001b[38;5;241m+\u001b[39m [\u001b[43mdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdef_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdl_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_subsets)]\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbunch_type(\u001b[38;5;241m*\u001b[39mdls, path\u001b[38;5;241m=\u001b[39mpath, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/text/data.py:218\u001b[0m, in \u001b[0;36mSortedDL.new\u001b[0;34m(self, dataset, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_res\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_res\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_res\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/data/core.py:97\u001b[0m, in \u001b[0;36mTfmdDL.new\u001b[0;34m(self, dataset, cls, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_n_inp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_types\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m         res\u001b[38;5;241m.\u001b[39m_n_inp,res\u001b[38;5;241m.\u001b[39m_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_inp,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/data/core.py:79\u001b[0m, in \u001b[0;36mTfmdDL._one_pass\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_one_pass\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     78\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_batch([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_item(\u001b[38;5;28;01mNone\u001b[39;00m)])\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: b \u001b[38;5;241m=\u001b[39m \u001b[43mto_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     its \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_batch(b)\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(its, (\u001b[38;5;28mlist\u001b[39m,\u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(its)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(its)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/torch_core.py:285\u001b[0m, in \u001b[0;36mto_device\u001b[0;34m(b, device, non_blocking)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m#         if hasattr(o, \"to_device\"): return o.to_device(device)\u001b[39;00m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m o\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/torch_core.py:222\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(func, x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApply `func` recursively to `x`, passing on args\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_listy(x): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(x)([apply(func, o, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x,\u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;28;01mreturn\u001b[39;00m {k: apply(func, v, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    224\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/torch_core.py:222\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(func, x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApply `func` recursively to `x`, passing on args\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_listy(x): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(x)([\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x,\u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;28;01mreturn\u001b[39;00m {k: apply(func, v, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    224\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/torch_core.py:223\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApply `func` recursively to `x`, passing on args\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_listy(x): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(x)([apply(func, o, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x,\u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;28;01mreturn\u001b[39;00m {k: apply(func, v, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    224\u001b[0m res \u001b[38;5;241m=\u001b[39m func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/torch_core.py:223\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApply `func` recursively to `x`, passing on args\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_listy(x): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(x)([apply(func, o, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x,\u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    224\u001b[0m res \u001b[38;5;241m=\u001b[39m func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/torch_core.py:224\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_listy(x): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(x)([apply(func, o, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x,\u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;28;01mreturn\u001b[39;00m {k: apply(func, v, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 224\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/fastai/torch_core.py:282\u001b[0m, in \u001b[0;36mto_device.<locals>._inner\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inner\u001b[39m(o):\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o,Tensor): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m#         if hasattr(o, \"to_device\"): return o.to_device(device)\u001b[39;00m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m o\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The MPS backend is supported on MacOS 12.3+.Current OS version can be queried using `sw_vers`"
     ]
    }
   ],
   "source": [
    "#Create mini-batch and define parameters\n",
    "hf_batch_tfm = Seq2SeqBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, \n",
    "    task='summarization',\n",
    "    text_gen_kwargs=\n",
    " {'max_length': 248,'min_length': 56,'do_sample': False, 'early_stopping': True, 'num_beams': 4, 'temperature': 1.0, \n",
    "  'top_k': 50, 'top_p': 1.0, 'repetition_penalty': 1.0, 'bad_words_ids': None, 'bos_token_id': 0, 'pad_token_id': 1,\n",
    " 'eos_token_id': 2, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'encoder_no_repeat_ngram_size': 0,\n",
    " 'num_return_sequences': 1, 'decoder_start_token_id': 2, 'use_cache': True, 'num_beam_groups': 1,\n",
    " 'diversity_penalty': 0.0, 'output_attentions': False, 'output_hidden_states': False, 'output_scores': False,\n",
    " 'return_dict_in_generate': False, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2, 'remove_invalid_values': False})\n",
    "\n",
    "\n",
    "#Prepare data for training\n",
    "blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=hf_batch_tfm), noop)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader('text'), get_y=ColReader('title'), splitter=RandomSplitter())\n",
    "dls = dblock.dataloaders(articles, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define performance metrics\n",
    "seq2seq_metrics = {\n",
    "        'rouge': {\n",
    "            'compute_kwargs': { 'rouge_types': [\"rouge1\", \"rouge2\", \"rougeL\"], 'use_stemmer': True },\n",
    "            'returns': [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "        },\n",
    "        'bertscore': {\n",
    "            'compute_kwargs': { 'lang': 'fr' },\n",
    "            'returns': [\"precision\", \"recall\", \"f1\"]}}\n",
    "\n",
    "#Model\n",
    "model = HF_BaseModelWrapper(hf_model)\n",
    "learn_cbs = [HF_BaseModelCallback]\n",
    "fit_cbs = [HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "#Specify training\n",
    "learn = Learner(dls, model,\n",
    "                opt_func=ranger,loss_func=CrossEntropyLossFlat(),\n",
    "                cbs=learn_cbs,splitter=partial(seq2seq_splitter, arch=hf_arch)).to_fp16()\n",
    "\n",
    "#Create optimizer with default hyper-parameters\n",
    "learn.create_opt() \n",
    "learn.freeze()\n",
    "\n",
    "#Training\n",
    "learn.fit_one_cycle(3, lr_max=3e-5, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = learn.blurr_generate(text_to_generate, early_stopping=False, num_return_sequences=1)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ff0138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a6930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe7c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "25375c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The words Extraordinary Claims needs to be banished when talking Extraterrestrials</td>\n",
       "      <td>The words Extraordinary Claims needs to be banished when talking Extraterrestrials page: 1 link I was reading an article that talked about Extraterrestrials the other day and of course at the end of the article the tired line about Extraordinary measures....blah, blah, blah came out towards the end of the article. This needs to stop when talking about Extraterrestrials. It may have been an extraordinary claim 60 years ago but it's not today. With the scientific evidence we have today, many people including one of the top Scientist of our time has reached the conclusion that Extraterrestria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We Know The Truth</td>\n",
       "      <td>link Hey People: I always enjoy your threads, though I think you focus too much on a singular belief issue or pattern, and then it becomes self affirming for you in your research. First, this: But voices actual voices in your head is always mental illness. Sorry, maybe a stress reaction, not to be judgmental, happens to the best and such, just really not what I am trying to convey here. Though I believe you are quite intelligent, I don't think you are qualified, exactly, to make that wholesale, definitive judgement. You even contradict that by referencing Dr. Vinod's \"channeling\" of the Ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UFO over the East Valley here in AZ last night.</td>\n",
       "      <td>UFO over the East Valley here in AZ last night. page: 1 link I couldn't take any pictures I live in West Mesa and the lights were way East. Over Queen Creek area. Lots of my friends and family started calling me right when the lights started happening so I went out to my balcony and there they were. Some people got some pretty good videos. I know some people will say they are flares from a plane but if they are flares why do they dispensary right away. Typically if its a flare it will stay ignited for a short period of time. Kinda nuts. I only witnessed the later 3 lights when it was dark ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Found this nugget in Podesta files Fastwalkers and DSP Program</td>\n",
       "      <td>Found this nugget in Podesta files Fastwalkers and DSP Program page: 1 Found this in the Podesta files, ID # 30433. It's probably well known already, just thought I'd post it just in case. Podesta had forwarded this letter he received onto Leslie Kean. Date: 2015-03-06 John ‚Äì Just tuck this in your UFO files for future reference. One of the government programs that collects hard data on unidentified flying objects is the USAF DSP satellite program. I can add a little insight to rumors published on the web. While I was never fully briefed into the DSP operation directly, I was introduced to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMP event forthcoming?</td>\n",
       "      <td>You have a work bunker? What is it exactly that you do? Man if the world went to crap, the last thing i would be concerned about is ensuring my employer keeps the loot rolling in lol. In fact if that does go down, im jumping in my truck with a motivational \"item\" and coming to work to stock up. The mine site has enough food for 500 people a for 2 weeks at a time. I live out in the country. Im On well water, 1000 liter propane tank for heat and out door boiler. The genny is hooked up to a 400 liter gas storage container. My house that im building up the road from my current house already ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Erica Garner blasts Clinton campaign over discussions staffers had about Eric Garner</td>\n",
       "      <td>Erica Garner blasts Clinton campaign over discussions staffers had about Eric Garner page: 1 One Podesta email has Clinton Campaign people discussing the death of Eric Garner in ways his Daughter Erica dislikes. She went on Twitter and gave them a piece of her mind. Seems they saw a newspaper story that may have been interpreted as a liability. This exposure could hurt the Campaign. The whole Campaign is based on political profits and losses, not Human dignity. Erica Garner blasts Clinton campaign over discussions staffers had about her father‚Äôs death in WikiLeaks emails Erica Garner, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Homeless TRUMP Supporter Guards Donald Trump's Star on Hollywood Blvd</td>\n",
       "      <td>Homeless TRUMP Supporter Guards Donald Trump‚Äôs Star on Hollywood Blvd page: 1 On Wednesday a violent leftist smashed Donald Trump‚Äôs star on the Hollywood Walk of Fame. The culprits used a sledgehammer to destroy Donald‚Äôs star. The person who was watching Trumps star had an anti-immigration sign and is pro-trump. Later another homeless man took up the watch to keep Trumps star on Hollywood BLVD safe. From the video it looks like the star had already been replaced. Could this be a plant? And has Trump secured the homeless vote? Everybody's looking for a gimmick, and their 15 minutes of fame....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Scientists say weird signals from space are 'probably' aliens</td>\n",
       "      <td>Scientists say weird signals from space are ‚Äòprobably‚Äô aliens A team of astronomers believes that strange signals emanating from a cluster of stars are actually aliens trying to tell the universe they exist. The study, which appeared in the Publications of the Astronomical Society of the Pacific, analyzed the odd beams of light from 234 stars ‚Äî a fraction of the 2.5 million that were observed. The bizarre beacons led the paper‚Äôs authors, Ermanno F. Borra and Eric Trottier from Laval University in Quebec, to conclude that it‚Äôs ‚Äúprobably‚Äù aliens. ‚ÄúWe find that the detected signals have exact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Can normal transistors act like a qubit?</td>\n",
       "      <td>Can normal transistors act like a qubit? page: 1 link Hi. I guess I have a question relating to quantum computing. Since qubits are what makes up quantum computers... That being a qubits can act like a transistor that can be either on, off, or both on and off at the same time. In usual computing... Transistors are either on or off. In quantum they can be both on and off at the same time... The question I have is simply this. Is it possible to make a transistor that can act as on, off, and on and off at the same time... Even if you had to add an extra layer of circuitry to get that same rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Podesta relative earned six-figure fees lobbying Clintons State Dept. during his tenure there</td>\n",
       "      <td>This is how it works in the Clinton Cabal...or is it the Mainstream Mafia. 1) Qatar supports ISIS (just by the way) 2) Qatar wants to buy advanced U.S. missile defence systems, Apache attack helicopters and other military materiel 3) Ratheon (a big defence contractor) wants to sell said U.S. Military goods to Qatar 4) These kinds of foreign military sales have to be approved by the State Department 5) Hillary becomes Secretary of State 6) Hillary has a \"Charitable Foundation\" 7) Hillary has a former POTUS as her spouse 8) Hillary has a network of aides, confidants, bundlers and fundraisers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            title  \\\n",
       "0              The words Extraordinary Claims needs to be banished when talking Extraterrestrials   \n",
       "1                                                                               We Know The Truth   \n",
       "2                                                 UFO over the East Valley here in AZ last night.   \n",
       "3                                  Found this nugget in Podesta files Fastwalkers and DSP Program   \n",
       "4                                                                          EMP event forthcoming?   \n",
       "..                                                                                            ...   \n",
       "95           Erica Garner blasts Clinton campaign over discussions staffers had about Eric Garner   \n",
       "96                          Homeless TRUMP Supporter Guards Donald Trump's Star on Hollywood Blvd   \n",
       "97                                  Scientists say weird signals from space are 'probably' aliens   \n",
       "98                                                       Can normal transistors act like a qubit?   \n",
       "99  Podesta relative earned six-figure fees lobbying Clintons State Dept. during his tenure there   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       text  \n",
       "0   The words Extraordinary Claims needs to be banished when talking Extraterrestrials page: 1 link I was reading an article that talked about Extraterrestrials the other day and of course at the end of the article the tired line about Extraordinary measures....blah, blah, blah came out towards the end of the article. This needs to stop when talking about Extraterrestrials. It may have been an extraordinary claim 60 years ago but it's not today. With the scientific evidence we have today, many people including one of the top Scientist of our time has reached the conclusion that Extraterrestria...  \n",
       "1   link Hey People: I always enjoy your threads, though I think you focus too much on a singular belief issue or pattern, and then it becomes self affirming for you in your research. First, this: But voices actual voices in your head is always mental illness. Sorry, maybe a stress reaction, not to be judgmental, happens to the best and such, just really not what I am trying to convey here. Though I believe you are quite intelligent, I don't think you are qualified, exactly, to make that wholesale, definitive judgement. You even contradict that by referencing Dr. Vinod's \"channeling\" of the Ni...  \n",
       "2   UFO over the East Valley here in AZ last night. page: 1 link I couldn't take any pictures I live in West Mesa and the lights were way East. Over Queen Creek area. Lots of my friends and family started calling me right when the lights started happening so I went out to my balcony and there they were. Some people got some pretty good videos. I know some people will say they are flares from a plane but if they are flares why do they dispensary right away. Typically if its a flare it will stay ignited for a short period of time. Kinda nuts. I only witnessed the later 3 lights when it was dark ...  \n",
       "3   Found this nugget in Podesta files Fastwalkers and DSP Program page: 1 Found this in the Podesta files, ID # 30433. It's probably well known already, just thought I'd post it just in case. Podesta had forwarded this letter he received onto Leslie Kean. Date: 2015-03-06 John ‚Äì Just tuck this in your UFO files for future reference. One of the government programs that collects hard data on unidentified flying objects is the USAF DSP satellite program. I can add a little insight to rumors published on the web. While I was never fully briefed into the DSP operation directly, I was introduced to...  \n",
       "4   You have a work bunker? What is it exactly that you do? Man if the world went to crap, the last thing i would be concerned about is ensuring my employer keeps the loot rolling in lol. In fact if that does go down, im jumping in my truck with a motivational \"item\" and coming to work to stock up. The mine site has enough food for 500 people a for 2 weeks at a time. I live out in the country. Im On well water, 1000 liter propane tank for heat and out door boiler. The genny is hooked up to a 400 liter gas storage container. My house that im building up the road from my current house already ha...  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...  \n",
       "95  Erica Garner blasts Clinton campaign over discussions staffers had about Eric Garner page: 1 One Podesta email has Clinton Campaign people discussing the death of Eric Garner in ways his Daughter Erica dislikes. She went on Twitter and gave them a piece of her mind. Seems they saw a newspaper story that may have been interpreted as a liability. This exposure could hurt the Campaign. The whole Campaign is based on political profits and losses, not Human dignity. Erica Garner blasts Clinton campaign over discussions staffers had about her father‚Äôs death in WikiLeaks emails Erica Garner, the ...  \n",
       "96  Homeless TRUMP Supporter Guards Donald Trump‚Äôs Star on Hollywood Blvd page: 1 On Wednesday a violent leftist smashed Donald Trump‚Äôs star on the Hollywood Walk of Fame. The culprits used a sledgehammer to destroy Donald‚Äôs star. The person who was watching Trumps star had an anti-immigration sign and is pro-trump. Later another homeless man took up the watch to keep Trumps star on Hollywood BLVD safe. From the video it looks like the star had already been replaced. Could this be a plant? And has Trump secured the homeless vote? Everybody's looking for a gimmick, and their 15 minutes of fame....  \n",
       "97  Scientists say weird signals from space are ‚Äòprobably‚Äô aliens A team of astronomers believes that strange signals emanating from a cluster of stars are actually aliens trying to tell the universe they exist. The study, which appeared in the Publications of the Astronomical Society of the Pacific, analyzed the odd beams of light from 234 stars ‚Äî a fraction of the 2.5 million that were observed. The bizarre beacons led the paper‚Äôs authors, Ermanno F. Borra and Eric Trottier from Laval University in Quebec, to conclude that it‚Äôs ‚Äúprobably‚Äù aliens. ‚ÄúWe find that the detected signals have exact...  \n",
       "98  Can normal transistors act like a qubit? page: 1 link Hi. I guess I have a question relating to quantum computing. Since qubits are what makes up quantum computers... That being a qubits can act like a transistor that can be either on, off, or both on and off at the same time. In usual computing... Transistors are either on or off. In quantum they can be both on and off at the same time... The question I have is simply this. Is it possible to make a transistor that can act as on, off, and on and off at the same time... Even if you had to add an extra layer of circuitry to get that same rea...  \n",
       "99  This is how it works in the Clinton Cabal...or is it the Mainstream Mafia. 1) Qatar supports ISIS (just by the way) 2) Qatar wants to buy advanced U.S. missile defence systems, Apache attack helicopters and other military materiel 3) Ratheon (a big defence contractor) wants to sell said U.S. Military goods to Qatar 4) These kinds of foreign military sales have to be approved by the State Department 5) Hillary becomes Secretary of State 6) Hillary has a \"Charitable Foundation\" 7) Hillary has a former POTUS as her spouse 8) Hillary has a network of aides, confidants, bundlers and fundraisers...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3476f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(list(articles['text'].values), list(articles['title'].values), test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa4728b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "def43065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98cc2fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "train_labels_encodings = tokenizer(train_labels, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "val_labels_encodings = tokenizer(val_labels, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "test_labels_encodings = tokenizer(test_labels, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8148a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = [torch.tensor(val[idx]) for key, val in self.encodings.items() if key=='input_ids'][0]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = IMDbDataset(train_encodings, train_labels_encodings)\n",
    "val_dataset = IMDbDataset(val_encodings, val_labels_encodings)\n",
    "test_dataset = IMDbDataset(test_encodings, test_labels_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc5dd4b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (2) to match target batch_size (1024).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 22\u001b[0m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m DistilBertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,                         \u001b[38;5;66;03m# the instantiated ü§ó Transformers model to be trained\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,                  \u001b[38;5;66;03m# training arguments, defined above\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,         \u001b[38;5;66;03m# training dataset\u001b[39;00m\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/transformers/trainer.py:1645\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1642\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1644\u001b[0m )\n\u001b[0;32m-> 1645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/transformers/trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1928\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1929\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1932\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1933\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1934\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1935\u001b[0m ):\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/transformers/trainer.py:2750\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2749\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2750\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2753\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/transformers/trainer.py:2775\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2774\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2775\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2776\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2777\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:797\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    796\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m--> 797\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    799\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/text_summarization/venv-summarization/lib/python3.10/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (2) to match target batch_size (1024)."
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertForSequenceClassification, AdamW\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(3):\n",
    "    for batch in train_loader:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
